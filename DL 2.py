# -*- coding: utf-8 -*-
"""DL Assignment_2_Updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Iy6pnwQzZT0_HTe7FZnjB2qlQQkZQ4u0
"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from torchvision.datasets import CIFAR10
from torch.optim import lr_scheduler
import math
import torch.nn.init as init
import torch.nn as nn
import torch.optim as optim
import time
import copy

preprocess_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

preprocess_test = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

trainset = CIFAR10(root='./data', train=True, download=True, transform=preprocess_train)

testset = CIFAR10(root='./data', train=False, download=True, transform=preprocess_test)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,
                                             shuffle=True, num_workers=4)
testloader = torch.utils.data.DataLoader(
    testset, batch_size=128, shuffle=False, num_workers=4)

def train(epoch,model,criterion,optimizer):
    print('\nEpoch: %d' % epoch)
    model.train()
    training_loss = 0
    corr = 0
    total = 0
    
    for batch_number, (input, target) in enumerate(trainloader):
        input, target = input.to('cuda'), target.to('cuda')
        optimizer.zero_grad()
        output = model(input)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        training_loss += loss.item()
        _, predic = output.max(1)
        total += target.size(0)
        corr += predic.eq(target).sum().item()
    print('Training Loss after '+str(epoch)+'is '+str(training_loss/batch_number+1))
    print('Training Accuracy after '+str(epoch)+'is '+str(100.*corr/total))
    return 100.*corr/total

def val(epoch,model,criterion,optimizer):
    global best_acc
    model.eval()
    val_loss = 0
    corr = 0
    total = 0

    with torch.no_grad():
        for batch_number, (input, target) in enumerate(testloader):
            input, target = input.to('cuda'), target.to('cuda')
            output = model(input)
            loss = criterion(output, target)

            val_loss += loss.item()
            _, predic = output.max(1)
            total += target.size(0)
            corr += predic.eq(target).sum().item()
        print('Testing Loss after '+str(epoch)+'is '+str(val_loss/batch_number+1))
        print('Testing Accuracy after '+str(epoch)+'is '+str(100.*corr/total))
    return 100.*corr/total

class vgg_custom(nn.Module):
    def __init__(self, features):
        super(vgg_custom, self).__init__()
        self.features = features
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512, 512),
            nn.SELU(True),
            nn.Dropout(0.5),
            nn.Linear(512, 512),
            nn.SELU(True),
            nn.Linear(512, 10),
        )
         # Initialize weights
        for i in self.modules():
            if isinstance(i, nn.Conv2d):
                j = i.kernel_size[0] * i.kernel_size[1] * i.out_channels
                i.weight.data.normal_(0, math.sqrt(2. / j))
                i.bias.data.zero_()


    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

def make_layer(batch_normmalization=True):
    vgg_configuration = [64, 64, 'Max', 128, 128, 'Max', 256, 256, 256, 'Max', 512, 512, 512, 'Max', 512, 512, 512, 'Max']
    layers = list()
    rgb_channels = 3
    for i in vgg_configuration:
        if i == 'Max':
            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
        else:
            conv2d = nn.Conv2d(rgb_channels, i, kernel_size=3, padding=1)
            layers += [conv2d, nn.BatchNorm2d(i), nn.SELU(inplace=True)]
            rgb_channels = i
    return nn.Sequential(*layers)

vgg = models.vgg16_bn()
vgg_custom = vgg_custom(make_layer(batch_normmalization=True))
# model = resnet18()
# inception = models.inception_v3()

vgg = vgg.to('cuda')
vgg_custom = vgg_custom.to('cuda')

criterion1 = nn.CrossEntropyLoss()
optimizer1 = optim.SGD(vgg_custom.parameters(), lr=0.01,
                      momentum=0.9, weight_decay=5e-4)

start_epoch = 1
end_epoch = 40
train_acc_custom = []
val_acc_custom = []
for epoch in range(start_epoch,end_epoch+1):
    since = time.time()
    t = train(epoch,vgg_custom,criterion1,optimizer1)
    train_acc_custom.append(t)
    v = val(epoch,vgg_custom,criterion1,optimizer1)
    val_acc_custom.append(v)
    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
    time_elapsed // 60, time_elapsed % 60))

criterion2 = nn.CrossEntropyLoss()
optimizer2 = optim.SGD(vgg.parameters(), lr=0.01,
                      momentum=0.9, weight_decay=5e-4)

start_epoch = 1
end_epoch = 40
train_acc = []
val_acc = []
for epoch in range(start_epoch,end_epoch+1):
    since = time.time()
    t = train(epoch,vgg,criterion2,optimizer2)
    train_acc.append(t)
    v = val(epoch,vgg,criterion2,optimizer2)
    val_acc.append(v)
    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
    time_elapsed // 60, time_elapsed % 60))

print(train_acc)
print(train_acc_custom)

import matplotlib.pyplot as plt
import numpy as np

plt.title("Training Accuracy vs.Training Epochs")
plt.xlabel("Training Epochs")
plt.ylabel("Training Accuracy")
plt.plot(range(1,end_epoch+1),train_acc_custom,label="Custom VGG16")
plt.plot(range(1,end_epoch+1),train_acc,label="Torchvision VGG16")
plt.xticks(np.arange(1, end_epoch+1, 1.0))
plt.legend()
plt.show()

plt.title("Validation Accuracy vs.Training Epochs")
plt.xlabel("Validation Epochs")
plt.ylabel("Training Accuracy")
plt.plot(range(1,end_epoch+1),val_acc_custom,label="Custom VGG16")
plt.plot(range(1,end_epoch+1),val_acc,label="Torchvision VGG16")
plt.xticks(np.arange(1, end_epoch+1, 1.0))
plt.legend()
plt.show()
